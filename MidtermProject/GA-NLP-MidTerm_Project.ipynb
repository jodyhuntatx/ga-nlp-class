{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A5on_E9xQSC"
   },
   "source": [
    "<center><p float=\"center\">\n",
    "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
    "</p></center>\n",
    "\n",
    "<h1><center><font size=10> Generative AI for NLP Program</center></font></h1>\n",
    "<h1><center> Project </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkypp72Oa4LD"
   },
   "source": [
    "# **GA-NLP Mid-Term Project: Financial Product Complaint Classification and Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exBRHi0DbHFT"
   },
   "source": [
    "## **Business Context**\n",
    "\n",
    "In today's financial landscape, customer complaints are pivotal for financial institutions, highlighting areas of dissatisfaction and guiding business improvements. The intricate task of classifying these complaints into specific product categories is crucial for understanding customer issues and enhancing service delivery. By employing Generative AI for text classification, businesses can gain a detailed understanding of customer grievances related to various financial products such as credit reports, student loans, and money transfers.\n",
    "\n",
    "The integration of machine learning algorithms has revolutionized the automation of customer complaint classification. Utilizing these advanced techniques, financial institutions can swiftly and accurately categorize new complaints based on their content. This automation not only saves time and resources but also ensures timely responses to customer issues, thereby improving customer satisfaction and compliance with regulatory standards.\n",
    "\n",
    "Additionally, this project will explore the summarization of customer narratives to provide more personalized solutions to complaints. By using Generative AI, businesses can enhance their ability to classify complaints more precisely and generate complaint summaries that facilitate more tailored and effective service responses.\n",
    "\n",
    "Embarking on this project of Financial Product Complaint Classification and Summarization, with a focus on classification and summarization accuracy, equips you with essential skills applicable to real-world business contexts. Through hands-on experience with code and implementation specifics, you'll gain the proficiency to build such solutions using open-source machine learning algorithms. This experience will serve as a compelling Proof-of-Concept, paving the way for the implementation of these advanced solutions in financial institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJfHP45hZpwW"
   },
   "source": [
    "## **Project Objective**\n",
    "\n",
    "Develop a Generative AI application using a Large Language Model to automate product classification and narrative summarization. This application will predict product categories, generate responses based on customer sentiment, and summarize narratives for the mediation team. We have been tackling this task with BERT and prompt engineering with LLMs. We will explore various techniques and select the most effective method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iz9eQKRzGBr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Section 1 BERT Fine Tuning (10 Marks)** (product classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg8yUa4sxWUI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 1: Installing the necessary packages and importing libraries (1 Mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwQFn8w-yloT"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import modules from scikit-learn for machine learning tasks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "# Import TensorFlow for deep learning tasks\n",
    "import tensorflow as tf\n",
    "\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl8ibWBGymnB"
   },
   "outputs": [],
   "source": [
    "# Import BertTokenizer, TFBertForSequenceClassification from the Hugging Face transformers library\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDdZSwFgTx9i"
   },
   "outputs": [],
   "source": [
    "# Set the seed for the TensorFlow random number generator to ensure reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFyPpwimzm7C",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 2: Data preprocessing for Bert Fine Tuning (2 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1iRBbNEz8AS"
   },
   "outputs": [],
   "source": [
    "# Load a CSV File containing Dataset of 500 products, narrative and summary (summary of narrative)\n",
    "data=pd.read_csv(\"./Complaints_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- product column is categorical\n",
    "- narrative text is already all lower case and needs no cleaning.\n",
    "- summary is mixed-case, may need cleaning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDJlPfhY0QtU"
   },
   "outputs": [],
   "source": [
    "#Bert_data=data['product','narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0OWEvhk0l9M"
   },
   "outputs": [],
   "source": [
    "# Creating dependent and independent variables from Bert_data\n",
    "train_test = data['narrative']\n",
    "y = data['product']\n",
    "# Further split the temporary set into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_test, y, test_size=0.20, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qscEhyvd1COV"
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# fit the encoder to the training labels\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "\n",
    "# applying the encoder mapping from training labels to test labels\n",
    "y_test_enc = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z6YF8gZ1MTc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 3: Tokenization (1 Mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xg5RWZtp2Puu"
   },
   "outputs": [],
   "source": [
    "# loading and creating an instance of the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# specifying the maximum length of the input 512\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPb5FlFR2UAk"
   },
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer(\n",
    "    X_train.values.tolist(),    # passing the data as a list to the tokenizer\n",
    "    max_length=max_length,    # specifies the maximum length of the tokenized data\n",
    "    padding='max_length',    # padding the data to the specified maximum length\n",
    "    truncation=True,    # truncating the input if it is longer than the specified maximum length\n",
    "    return_attention_mask=True,    # specifying to return attention masks\n",
    "    return_tensors='tf',    # specifying to return the output as tensorflow tensors\n",
    ")\n",
    "X_test_tokenized = tokenizer(\n",
    "    X_test.values.tolist(),\n",
    "    max_length=max_length,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='tf',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raT2V3lU2x_Q",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 4: Creating Tensorflow dataset (1 Mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63e-GNZT2wkP"
   },
   "outputs": [],
   "source": [
    "# defining the size of the batches\n",
    "batch_size = 8\n",
    "\n",
    "# convert the tokenized input and the output into a batched tensorflow dataset for training\n",
    "train_tokenized_tf = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized), y_train_enc)).batch(batch_size)\n",
    "\n",
    "# convert the tokenized input and the output into a batched tensorflow dataset for testing\n",
    "test_tokenized_tf = tf.data.Dataset.from_tensor_slices((dict(X_test_tokenized), y_test_enc)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSSSVjqe3M54",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 5 Evaluating the base model's performance in product classification.(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7mCVcuE4Dzn"
   },
   "outputs": [],
   "source": [
    "def bert_f1_score(actual_vals, pred_vals):\n",
    "    micro_f1_score = f1_score(actual_vals, pred_vals, average=\"micro\")\n",
    "    return micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL5hdRna6MW_"
   },
   "outputs": [],
   "source": [
    "# Actual product class\n",
    "actual_val = np.concatenate([y for x, y in test_tokenized_tf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.nunique()\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnQnyS-93G9O"
   },
   "outputs": [],
   "source": [
    "# Initialize Model using BERT for sequence classification\n",
    "base_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary of the model\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test_tokenized_tf\n",
    "preds_raw_test = base_model.predict(test_tokenized_tf)\n",
    "preds_test_base = np.argmax(np.array(tf.nn.softmax(preds_raw_test.logits)), axis=1)\n",
    "preds_test_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_base[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9oa8YPR5D0z"
   },
   "outputs": [],
   "source": [
    "# Evaluate bert base model\n",
    "base_f1_score = bert_f1_score(y_test_enc, preds_test_base)\n",
    "print(base_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Untrained model performance is really bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UVe2kiB510Z",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 6 Fine-Tuning Bert Model on training set (2 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Shjp4bPVlfMh"
   },
   "outputs": [],
   "source": [
    "num_classes = y.nunique()\n",
    "# Model initialization using BERT for sequence classification\n",
    "ft_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1Psz_7a59TU"
   },
   "outputs": [],
   "source": [
    "# setting the learning rate for the optimizer\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Setting the optimizer to Adam\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "\n",
    "# Specify the loss function for the model\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Define evaluation metric(s) for the model\n",
    "metric = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
    "\n",
    "# Compile the model with the chosen optimizer, loss function, and metrics\n",
    "ft_model.compile(optimizer=optimizer, loss=loss, metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJiQN-mb6kIn"
   },
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced dataset\n",
    "cw = (y_train_enc.shape[0]) / np.bincount(y_train_enc)\n",
    "\n",
    "# Create a dictionary mapping class indices to their respective class weights\n",
    "cw_dict = {}\n",
    "for i in range(cw.shape[0]):\n",
    "    cw_dict[encoder.transform(encoder.classes_)[i]] = cw[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YzNLc2n96oT_"
   },
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "n_epochs = 1\n",
    "#train bert model\n",
    "bert_base_tuned = ft_model.fit(train_tokenized_tf, epochs=n_epochs, class_weight=cw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ43M02s68Uf",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 7. Evaluating the trained model performance (1 Mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wd890cvZ61_o"
   },
   "outputs": [],
   "source": [
    "# Generate raw predictions on the test dataset using the trained model\n",
    "preds_raw_val_ft = ft_model.predict(test_tokenized_tf)\n",
    "\n",
    "# Extract predicted labels by finding the index with the highest probability for each example\n",
    "preds_val_ft = np.argmax(np.array(tf.nn.softmax(preds_raw_val_ft.logits)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_ft[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D33p2Wqn7Tgq"
   },
   "outputs": [],
   "source": [
    "# Evaluate bert trained model\n",
    "ft_f1_score = bert_f1_score(y_test_enc, preds_val_ft)\n",
    "print(ft_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iBOLR6a7dbZ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 8: Write your observations (1 Mark)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training improved f1 score dramatically, from 0.09 to 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSiuLz5JCLQI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Section 2: Install Libraries for Prompt Engineering and Setting up Mistral Model (3 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcGMygn3_Mq9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 9: Install necessary libraries (1 Mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "gl0E64ce8Uct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_cpp_python             0.2.84\n",
      "huggingface-hub              0.24.2\n",
      "evaluate                     0.4.1\n",
      "bert-score                   0.3.12\n",
      "numpy                        1.25.2\n"
     ]
    }
   ],
   "source": [
    "# Installation for GPU llama_cpp_python==0.2.28\n",
    "!pip list | grep llama_cpp_python\n",
    "# For downloading the models from HF Hub huggingface-hub==0.23.2\n",
    "!pip list | grep huggingface-hub\n",
    "# install evaluate==0.4.2 and bert-score==0.3.13 using pip command\n",
    "!pip list | grep evaluate\n",
    "!pip list | grep bert-score\n",
    "# install numpy==1.25.2\n",
    "!pip list | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "TsrUPUGTANTi"
   },
   "outputs": [],
   "source": [
    "# Basic Imports for Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# Import visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "#from google.colab import drive\n",
    "import locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV File containing Dataset of 500 products, narrative and summary (summary of narrative)\n",
    "data=pd.read_csv(\"./Complaints_classification.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdQdNav7AOtV",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Question 10: Importing Libaries and Setting up Mistral Model (2 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO7TfAEiSxMR"
   },
   "source": [
    "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/blob/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "cpQlIfeqAkvz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-2-13b-chat.Q5_K_M.gguf  mistral-7b-instruct-v0.2.Q5_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "## Import Hf_hub_download from hugging_face_hub\n",
    "!ls /home/ubuntu/models\n",
    "\n",
    "## Import Llama from llama_cpp\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "e9c3ISlwftKB"
   },
   "outputs": [],
   "source": [
    "# Define the model name or path as a string (You can find this info from hugging face website) Use Mistral\n",
    "\n",
    "model_basepath = \"/home/ubuntu/models/\"\n",
    "\n",
    "# Define the model name as a string, indicating it's in the gguf format\n",
    "\n",
    "model_name = \"mistral-7b-instruct-v0.2.Q5_K_M.gguf\" # the model is in gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vvPmPoy4wCIc"
   },
   "outputs": [],
   "source": [
    "model_path = model_basepath+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "R7Sm6O-jfzRo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /home/ubuntu/models/mistral-7b-instruct-v0.2.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 3\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.27 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4807.05 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   296.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    16.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the 'Llama' class with specified parameters\n",
    "# remove the blank spaces and complete the code\n",
    "\n",
    "lcpp_llm = Llama(\n",
    "        model_path=model_path,\n",
    "        n_threads=2,  # CPU cores\n",
    "        n_batch=512,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "        n_gpu_layers=43,  # Change this value based on your model and your GPU VRAM pool.\n",
    "        n_ctx=4096,  # Context window\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj8Gk-m1Iz1q"
   },
   "source": [
    "# **Section 3: Text to Label (12 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6xcR3o2ga6p",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Zero-Shot Prompting (6 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ8ual1jghmN"
   },
   "source": [
    "### **Q11: Define the Prompt Template, System Message, generate_prompt** **(3 Marks)**\n",
    "\n",
    "Define a **system message** as a string and assign it to the variable system_message to generate product class.\n",
    "\n",
    "Create a **zero shot prompt template** that incorporates the system message and user input.\n",
    "\n",
    "Define **generate_prompt** function that takes both the system_message and user_input as arguments and formats them into a prompt template\n",
    "\n",
    "\n",
    "Write a Python function called **generate_mistral_response** that takes a single parameter, narrative, which represents the user's complain. Inside the function, you should perform the following tasks:\n",
    "\n",
    "\n",
    "- **Combine the system_message and narrative to create a prompt string using generate_prompt function.**\n",
    "\n",
    "*Generate a response from the Mistral model using the lcpp_llm instance with the following parameters:*\n",
    "\n",
    "- prompt should be the combined prompt string.\n",
    "- max_tokens should be set to 1200.\n",
    "- temperature should be set to 0.\n",
    "- top_p should be set to 0.95.\n",
    "- repeat_penalty should be set to 1.2.\n",
    "- top_k should be set to 50.\n",
    "- stop should be set as a list containing '/s'.\n",
    "- echo should be set to False.\n",
    "Extract and return the response text from the generated response.\n",
    "\n",
    "Don't forget to provide a value for the system_message variable before using it in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QIMDLp51ghGr"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are an AI evaluating the input text below to generate a singular product classification.\n",
    "Be concise.  Do not provide any explanation. Respond only with the product classification.\n",
    "A product classification is exactly one of:\n",
    "- credit_card\n",
    "- retail_banking\n",
    "- credit_reporting\n",
    "- mortgages_and_loans\n",
    "- debt_collection\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e24qaY7ug2CC"
   },
   "outputs": [],
   "source": [
    "zero_shot_prompt_template = \"{input}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JKOyehERgy77"
   },
   "outputs": [],
   "source": [
    "# Define function that combines user_prompt and system_message to create the prompt\n",
    "def generate_prompt(_system_message, _user_input):\n",
    "    _prompt = f\"[INST]\\n<<SYS>>\\n{_system_message}\\n<<SYS>>\\n{_user_input}\\n[/INST]\"\n",
    "    return _prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "<<SYS>>\n",
      "You are an AI evaluating the input text below to generate a singular product classification.\n",
      "Be concise.  Do not provide any explanation. Respond only with the product classification.\n",
      "A product classification is exactly one of:\n",
      "- credit_card\n",
      "- retail_banking\n",
      "- credit_reporting\n",
      "- mortgages_and_loans\n",
      "- debt_collection\n",
      "\n",
      "<<SYS>>\n",
      "this is the user input\n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(system_message, \"this is the user input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3PJcu3dwg7FO"
   },
   "outputs": [],
   "source": [
    "def generate_mistral_response(_sys_message, input_text):\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt=generate_prompt(_sys_message, input_text)\n",
    "    # Generate a response from the LLaMA model\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1200,\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=['/s'],\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "    # Extract and return the response text\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmFU17EpyeKg"
   },
   "source": [
    "**Due to limited GPU resources, we will test our model with zero prompts on only 50 examples instead of the entire dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xhwItJrIhNta"
   },
   "outputs": [],
   "source": [
    "# Randomly select 50 rows\n",
    "new_data = data.sample(n=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-GrdMrVkaei"
   },
   "source": [
    "### **Q12: Create a new column in the DataFrame called 'mistral_response' and populate it with responses generated by applying the 'generate_mistral_response' function to each 'narrative' in the DataFrame and prepare the mistral_response_cleaned column using extract_category function** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BqEme1elh24Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2030.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.69 ms /   512 tokens (    1.24 ms per token,   809.25 tokens per second)\n",
      "llama_print_timings:        eval time =     134.96 ms /     5 runs   (   26.99 ms per token,    37.05 tokens per second)\n",
      "llama_print_timings:       total time =     773.08 ms /   517 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /     9 runs   (    0.52 ms per token,  1932.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =      60.88 ms /    33 tokens (    1.84 ms per token,   542.06 tokens per second)\n",
      "llama_print_timings:        eval time =     208.78 ms /     8 runs   (   26.10 ms per token,    38.32 tokens per second)\n",
      "llama_print_timings:       total time =     279.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     5 runs   (    0.49 ms per token,  2048.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     426.66 ms /   420 tokens (    1.02 ms per token,   984.39 tokens per second)\n",
      "llama_print_timings:        eval time =     108.00 ms /     4 runs   (   27.00 ms per token,    37.04 tokens per second)\n",
      "llama_print_timings:       total time =     540.02 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1959.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     121.37 ms /   117 tokens (    1.04 ms per token,   964.03 tokens per second)\n",
      "llama_print_timings:        eval time =     102.89 ms /     4 runs   (   25.72 ms per token,    38.88 tokens per second)\n",
      "llama_print_timings:       total time =     229.50 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     4 runs   (    0.51 ms per token,  1948.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.58 ms /    26 tokens (    2.02 ms per token,   494.48 tokens per second)\n",
      "llama_print_timings:        eval time =      78.24 ms /     3 runs   (   26.08 ms per token,    38.34 tokens per second)\n",
      "llama_print_timings:       total time =     134.34 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     5 runs   (    0.50 ms per token,  1986.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     422.51 ms /   420 tokens (    1.01 ms per token,   994.05 tokens per second)\n",
      "llama_print_timings:        eval time =     107.33 ms /     4 runs   (   26.83 ms per token,    37.27 tokens per second)\n",
      "llama_print_timings:       total time =     534.61 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2033.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     137.29 ms /     5 runs   (   27.46 ms per token,    36.42 tokens per second)\n",
      "llama_print_timings:       total time =     141.59 ms /     5 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     5 runs   (    0.50 ms per token,  2011.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     158.11 ms /   157 tokens (    1.01 ms per token,   992.95 tokens per second)\n",
      "llama_print_timings:        eval time =     103.78 ms /     4 runs   (   25.95 ms per token,    38.54 tokens per second)\n",
      "llama_print_timings:       total time =     267.18 ms /   161 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /     5 runs   (    0.55 ms per token,  1826.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =      72.09 ms /    52 tokens (    1.39 ms per token,   721.31 tokens per second)\n",
      "llama_print_timings:        eval time =     104.87 ms /     4 runs   (   26.22 ms per token,    38.14 tokens per second)\n",
      "llama_print_timings:       total time =     181.87 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     9 runs   (    0.51 ms per token,  1978.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =      75.95 ms /    60 tokens (    1.27 ms per token,   789.98 tokens per second)\n",
      "llama_print_timings:        eval time =     211.16 ms /     8 runs   (   26.39 ms per token,    37.89 tokens per second)\n",
      "llama_print_timings:       total time =     294.16 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     5 runs   (    0.49 ms per token,  2021.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.46 ms /   336 tokens (    0.98 ms per token,  1016.76 tokens per second)\n",
      "llama_print_timings:        eval time =     107.75 ms /     4 runs   (   26.94 ms per token,    37.12 tokens per second)\n",
      "llama_print_timings:       total time =     443.66 ms /   340 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     5 runs   (    0.52 ms per token,  1932.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     483.38 ms /   511 tokens (    0.95 ms per token,  1057.14 tokens per second)\n",
      "llama_print_timings:        eval time =     108.72 ms /     4 runs   (   27.18 ms per token,    36.79 tokens per second)\n",
      "llama_print_timings:       total time =     598.34 ms /   515 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     5 runs   (    0.48 ms per token,  2062.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     422.32 ms /   420 tokens (    1.01 ms per token,   994.50 tokens per second)\n",
      "llama_print_timings:        eval time =     109.24 ms /     4 runs   (   27.31 ms per token,    36.62 tokens per second)\n",
      "llama_print_timings:       total time =     535.64 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     4 runs   (    0.54 ms per token,  1853.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.16 ms /   178 tokens (    1.03 ms per token,   966.57 tokens per second)\n",
      "llama_print_timings:        eval time =      79.29 ms /     3 runs   (   26.43 ms per token,    37.84 tokens per second)\n",
      "llama_print_timings:       total time =     268.12 ms /   181 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     420.26 ms /   420 tokens (    1.00 ms per token,   999.37 tokens per second)\n",
      "llama_print_timings:        eval time =     107.25 ms /     4 runs   (   26.81 ms per token,    37.29 tokens per second)\n",
      "llama_print_timings:       total time =     532.68 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /     5 runs   (    0.49 ms per token,  2037.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     137.38 ms /     5 runs   (   27.48 ms per token,    36.40 tokens per second)\n",
      "llama_print_timings:       total time =     141.76 ms /     5 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /     5 runs   (    0.47 ms per token,  2111.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     122.27 ms /   121 tokens (    1.01 ms per token,   989.62 tokens per second)\n",
      "llama_print_timings:        eval time =     104.89 ms /     4 runs   (   26.22 ms per token,    38.14 tokens per second)\n",
      "llama_print_timings:       total time =     231.56 ms /   125 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     4 runs   (    0.54 ms per token,  1868.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.16 ms /   115 tokens (    1.07 ms per token,   933.73 tokens per second)\n",
      "llama_print_timings:        eval time =      77.81 ms /     3 runs   (   25.94 ms per token,    38.56 tokens per second)\n",
      "llama_print_timings:       total time =     204.82 ms /   118 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     5 runs   (    0.49 ms per token,  2056.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.12 ms /   421 tokens (    1.01 ms per token,   992.64 tokens per second)\n",
      "llama_print_timings:        eval time =     106.87 ms /     4 runs   (   26.72 ms per token,    37.43 tokens per second)\n",
      "llama_print_timings:       total time =     536.01 ms /   425 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2036.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     419.31 ms /   420 tokens (    1.00 ms per token,  1001.64 tokens per second)\n",
      "llama_print_timings:        eval time =     110.41 ms /     4 runs   (   27.60 ms per token,    36.23 tokens per second)\n",
      "llama_print_timings:       total time =     534.72 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     5 runs   (    0.55 ms per token,  1813.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     123.92 ms /   128 tokens (    0.97 ms per token,  1032.95 tokens per second)\n",
      "llama_print_timings:        eval time =     104.78 ms /     4 runs   (   26.19 ms per token,    38.18 tokens per second)\n",
      "llama_print_timings:       total time =     233.89 ms /   132 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /     5 runs   (    0.55 ms per token,  1822.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     113.34 ms /   103 tokens (    1.10 ms per token,   908.81 tokens per second)\n",
      "llama_print_timings:        eval time =     103.58 ms /     4 runs   (   25.89 ms per token,    38.62 tokens per second)\n",
      "llama_print_timings:       total time =     222.01 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2030.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.93 ms /   432 tokens (    0.98 ms per token,  1016.63 tokens per second)\n",
      "llama_print_timings:        eval time =     107.45 ms /     4 runs   (   26.86 ms per token,    37.23 tokens per second)\n",
      "llama_print_timings:       total time =     537.90 ms /   436 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     5 runs   (    0.49 ms per token,  2049.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.32 ms /   421 tokens (    1.01 ms per token,   992.17 tokens per second)\n",
      "llama_print_timings:        eval time =     107.70 ms /     4 runs   (   26.93 ms per token,    37.14 tokens per second)\n",
      "llama_print_timings:       total time =     536.62 ms /   425 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /     4 runs   (    0.47 ms per token,  2129.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =      46.26 ms /    18 tokens (    2.57 ms per token,   389.09 tokens per second)\n",
      "llama_print_timings:        eval time =      77.59 ms /     3 runs   (   25.86 ms per token,    38.67 tokens per second)\n",
      "llama_print_timings:       total time =     127.19 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     4 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.44 ms /   182 tokens (    1.02 ms per token,   981.46 tokens per second)\n",
      "llama_print_timings:        eval time =      79.56 ms /     3 runs   (   26.52 ms per token,    37.71 tokens per second)\n",
      "llama_print_timings:       total time =     268.12 ms /   185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     5 runs   (    0.46 ms per token,  2186.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      53.95 ms /    32 tokens (    1.69 ms per token,   593.19 tokens per second)\n",
      "llama_print_timings:        eval time =     109.54 ms /     4 runs   (   27.39 ms per token,    36.52 tokens per second)\n",
      "llama_print_timings:       total time =     167.75 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     5 runs   (    0.52 ms per token,  1939.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     483.02 ms /   511 tokens (    0.95 ms per token,  1057.92 tokens per second)\n",
      "llama_print_timings:        eval time =     108.06 ms /     4 runs   (   27.02 ms per token,    37.02 tokens per second)\n",
      "llama_print_timings:       total time =     595.76 ms /   515 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     4 runs   (    0.43 ms per token,  2308.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     111.38 ms /   101 tokens (    1.10 ms per token,   906.81 tokens per second)\n",
      "llama_print_timings:        eval time =      77.67 ms /     3 runs   (   25.89 ms per token,    38.62 tokens per second)\n",
      "llama_print_timings:       total time =     192.84 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2033.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     426.25 ms /   421 tokens (    1.01 ms per token,   987.68 tokens per second)\n",
      "llama_print_timings:        eval time =     107.54 ms /     4 runs   (   26.88 ms per token,    37.20 tokens per second)\n",
      "llama_print_timings:       total time =     538.73 ms /   425 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     5 runs   (    0.53 ms per token,  1899.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =      75.98 ms /    52 tokens (    1.46 ms per token,   684.35 tokens per second)\n",
      "llama_print_timings:        eval time =     104.64 ms /     4 runs   (   26.16 ms per token,    38.23 tokens per second)\n",
      "llama_print_timings:       total time =     185.15 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     5 runs   (    0.49 ms per token,  2045.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.15 ms /   421 tokens (    1.01 ms per token,   994.92 tokens per second)\n",
      "llama_print_timings:        eval time =     107.91 ms /     4 runs   (   26.98 ms per token,    37.07 tokens per second)\n",
      "llama_print_timings:       total time =     536.03 ms /   425 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1917.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     112.64 ms /   109 tokens (    1.03 ms per token,   967.68 tokens per second)\n",
      "llama_print_timings:        eval time =     104.39 ms /     4 runs   (   26.10 ms per token,    38.32 tokens per second)\n",
      "llama_print_timings:       total time =     220.73 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     5 runs   (    0.52 ms per token,  1926.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     480.38 ms /   505 tokens (    0.95 ms per token,  1051.25 tokens per second)\n",
      "llama_print_timings:        eval time =     107.92 ms /     4 runs   (   26.98 ms per token,    37.06 tokens per second)\n",
      "llama_print_timings:       total time =     593.63 ms /   509 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    20 runs   (    0.54 ms per token,  1861.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.20 ms /   205 tokens (    1.02 ms per token,   979.91 tokens per second)\n",
      "llama_print_timings:        eval time =     520.15 ms /    19 runs   (   27.38 ms per token,    36.53 tokens per second)\n",
      "llama_print_timings:       total time =     748.42 ms /   224 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     5 runs   (    0.49 ms per token,  2033.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.18 ms /   437 tokens (    0.99 ms per token,  1013.51 tokens per second)\n",
      "llama_print_timings:        eval time =     109.42 ms /     4 runs   (   27.36 ms per token,    36.56 tokens per second)\n",
      "llama_print_timings:       total time =     545.46 ms /   441 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     5 runs   (    0.48 ms per token,  2062.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     425.97 ms /   420 tokens (    1.01 ms per token,   985.99 tokens per second)\n",
      "llama_print_timings:        eval time =     108.68 ms /     4 runs   (   27.17 ms per token,    36.81 tokens per second)\n",
      "llama_print_timings:       total time =     538.91 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     5 runs   (    0.53 ms per token,  1871.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =      74.92 ms /    52 tokens (    1.44 ms per token,   694.09 tokens per second)\n",
      "llama_print_timings:        eval time =     105.25 ms /     4 runs   (   26.31 ms per token,    38.00 tokens per second)\n",
      "llama_print_timings:       total time =     184.65 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1957.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     485.14 ms /   511 tokens (    0.95 ms per token,  1053.29 tokens per second)\n",
      "llama_print_timings:        eval time =     108.34 ms /     4 runs   (   27.08 ms per token,    36.92 tokens per second)\n",
      "llama_print_timings:       total time =     598.70 ms /   515 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     5 runs   (    0.50 ms per token,  2019.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.14 ms /   198 tokens (    1.06 ms per token,   942.25 tokens per second)\n",
      "llama_print_timings:        eval time =     108.36 ms /     4 runs   (   27.09 ms per token,    36.91 tokens per second)\n",
      "llama_print_timings:       total time =     323.08 ms /   202 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     5 runs   (    0.49 ms per token,  2061.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     426.42 ms /   420 tokens (    1.02 ms per token,   984.95 tokens per second)\n",
      "llama_print_timings:        eval time =     109.62 ms /     4 runs   (   27.41 ms per token,    36.49 tokens per second)\n",
      "llama_print_timings:       total time =     541.16 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    17 runs   (    0.52 ms per token,  1921.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =      52.92 ms /    31 tokens (    1.71 ms per token,   585.79 tokens per second)\n",
      "llama_print_timings:        eval time =     430.01 ms /    16 runs   (   26.88 ms per token,    37.21 tokens per second)\n",
      "llama_print_timings:       total time =     497.75 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      20.32 ms /    39 runs   (    0.52 ms per token,  1919.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =      63.57 ms /    44 tokens (    1.44 ms per token,   692.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1028.49 ms /    38 runs   (   27.07 ms per token,    36.95 tokens per second)\n",
      "llama_print_timings:       total time =    1130.15 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     5 runs   (    0.52 ms per token,  1935.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     483.15 ms /   511 tokens (    0.95 ms per token,  1057.64 tokens per second)\n",
      "llama_print_timings:        eval time =     109.95 ms /     4 runs   (   27.49 ms per token,    36.38 tokens per second)\n",
      "llama_print_timings:       total time =     598.24 ms /   515 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     4 runs   (    0.53 ms per token,  1870.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     124.36 ms /   123 tokens (    1.01 ms per token,   989.06 tokens per second)\n",
      "llama_print_timings:        eval time =      77.88 ms /     3 runs   (   25.96 ms per token,    38.52 tokens per second)\n",
      "llama_print_timings:       total time =     206.25 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /     9 runs   (    0.53 ms per token,  1890.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     156.96 ms /   134 tokens (    1.17 ms per token,   853.74 tokens per second)\n",
      "llama_print_timings:        eval time =     214.37 ms /     8 runs   (   26.80 ms per token,    37.32 tokens per second)\n",
      "llama_print_timings:       total time =     381.23 ms /   142 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     5 runs   (    0.51 ms per token,  1948.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.57 ms /   290 tokens (    1.12 ms per token,   890.75 tokens per second)\n",
      "llama_print_timings:        eval time =     107.39 ms /     4 runs   (   26.85 ms per token,    37.25 tokens per second)\n",
      "llama_print_timings:       total time =     438.18 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    38 runs   (    0.52 ms per token,  1915.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =      62.94 ms /    39 tokens (    1.61 ms per token,   619.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1005.94 ms /    37 runs   (   27.19 ms per token,    36.78 tokens per second)\n",
      "llama_print_timings:       total time =    1104.71 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     5 runs   (    0.49 ms per token,  2061.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.46 ms /   420 tokens (    1.01 ms per token,   991.84 tokens per second)\n",
      "llama_print_timings:        eval time =     109.83 ms /     4 runs   (   27.46 ms per token,    36.42 tokens per second)\n",
      "llama_print_timings:       total time =     538.23 ms /   424 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      81.53 ms /   155 runs   (    0.53 ms per token,  1901.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     128.64 ms /   122 tokens (    1.05 ms per token,   948.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4232.30 ms /   154 runs   (   27.48 ms per token,    36.39 tokens per second)\n",
      "llama_print_timings:       total time =    4519.83 ms /   276 tokens\n"
     ]
    }
   ],
   "source": [
    "# capture lengthy model timing output to variable\n",
    "%%capture gen_out\n",
    "new_data['mistral_response'] = new_data['narrative'].apply(lambda x: generate_mistral_response(system_message, zero_shot_prompt_template.format(input=x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistral_response\n",
       "credit_reporting                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     27\n",
       "debt_collection                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       7\n",
       "credit\\_reporting                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     6\n",
       "retail_banking                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2\n",
       "mortgages_and_loans                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2\n",
       "mortgages\\_and\\_loans                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "credit_reporting or debt_collection (depending on the specific context of the text)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
       "Based on the input text, the product classification is: credit\\_reporting.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "credit\\_reporting. This text appears to be related to a discussion about identity fraud and the unauthorized use of personal information for credit applications, which falls under the category of credit reporting.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "credit\\_card. This text appears to be related to a credit card product or service, specifically discussing Amex and late fees during the New York State COVID-19 relief plan.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Based on the input text, it appears to be discussing a vehicle sale transaction. However, there are no clear indications of specific product classifications such as credit cards, retail banking, credit reporting, mortgages and loans, or debt collection. Therefore, I cannot provide a definitive product classification based on this text alone.\\n\\nHowever, if we had to make an educated guess based on the context, it seems that this transaction may involve some elements of both retail banking (sale of used vehicle) and possibly mortgages and loans (mention of existing lease deal and payoff amount). But without more information, it's difficult to be certain.\\n\\nTherefore, I cannot provide a definitive product classification based on the given text.     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['mistral_response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "10Bulypzkwjt"
   },
   "outputs": [],
   "source": [
    "def extract_category(text):\n",
    "    # Define the regex pattern to match \"category:\" or \"Category:\" followed by a word\n",
    "    pattern = r'category:\\s*(\\w+)'  # The pattern itself remains the same\n",
    "\n",
    "    # Use re.search with the re.IGNORECASE flag to make it case-insensitive\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    # If a match is found, return the captured group, else return None\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        pattern1 = r'(credit_card|retail_banking|credit_reporting|mortgages_and_loans|debt_collection)'\n",
    "        match = re.search(pattern1, text.replace('\\_','_'), re.IGNORECASE) # strip out random backslashes before '_'\n",
    "        if match:\n",
    "            return match.group()\n",
    "        else:\n",
    "            print(\"\\nNo match: \", text)\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "w-REbjsCnhaq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match:   Based on the input text, it appears to be discussing a vehicle sale transaction. However, there are no clear indications of specific product classifications such as credit cards, retail banking, credit reporting, mortgages and loans, or debt collection. Therefore, I cannot provide a definitive product classification based on this text alone.\n",
      "\n",
      "However, if we had to make an educated guess based on the context, it seems that this transaction may involve some elements of both retail banking (sale of used vehicle) and possibly mortgages and loans (mention of existing lease deal and payoff amount). But without more information, it's difficult to be certain.\n",
      "\n",
      "Therefore, I cannot provide a definitive product classification based on the given text.\n"
     ]
    }
   ],
   "source": [
    "# example - new_data['mistral_response_cleaned'] = new_data['narrative'].apply(lambda x:______ )\n",
    "new_data['mistral_response_cleaned'] = new_data['mistral_response'].apply(lambda x: extract_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       37\n",
       "credit_card             5\n",
       "mortgages_and_loans     4\n",
       "retail_banking          3\n",
       "debt_collection         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['mistral_response_cleaned'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9t6gsZVsL2b"
   },
   "source": [
    "### **Q14: Calculate the F1 score** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CeUoZb4ttDCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for 'product' and 'mistral_response'\n",
    "f1_1 =  f1_score(new_data['product'], new_data['mistral_response'], average=\"micro\")\n",
    "print(f'F1 Score: {f1_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ynzQvTi8tCcp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for 'product' and 'mistral_response_cleaned'\n",
    "f1_2 =  f1_score(new_data['product'], new_data['mistral_response_cleaned'], average=\"micro\")\n",
    "print(f'F1 Score: {f1_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "803ZuG7OtSSj"
   },
   "source": [
    "### **Q15: Explain the difference in F1 scores between mistral_response and mistral_response_cleaned.** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score is zero for the raw Mistral responses because the none of the response values exactly match the actual categorical value.<br>\n",
    "The F1 score for the cleaned Mistral responses shows the model achieved a reasonable degree of accuracy once the raw responses were mapped to one of the five categories.<br>\n",
    "The most mis-categorized feature values were:<br>\n",
    " - credit_card\n",
    " - credit_reporting\n",
    " - retail_banking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating confusion matrix\n",
    "cnf_mt = confusion_matrix(new_data['product'], new_data['mistral_response_cleaned'])\n",
    "\n",
    "# Visualizing confusion matrix using a heatmap\n",
    "num_cats = new_data['mistral_response_cleaned'].value_counts().shape[0]\n",
    "if num_cats == 5:\n",
    "  labels=['credit_card','credit_reporting','debt_collection','mortgages_and_loans','retail_banking']\n",
    "elif num_cats == 6:\n",
    "  labels=['<no-match>','credit_card','credit_reporting','debt_collection','mortgages_and_loans','retail_banking']\n",
    "    \n",
    "sns.heatmap(cnf_mt, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0YUCSXAnx3y"
   },
   "source": [
    "## **Few-Shot Prompting (6 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgxdRjW_wHId"
   },
   "source": [
    "### **Q16: Prepare examples for a few-shot prompt, formulate the prompt, and generate the Mistral response. (4 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPuH7_ravBtS"
   },
   "source": [
    "**Generate a set of gold examples by randomly selecting 10 instances of user_input and assistant_output from dataset ensuring a balanced representation with 2 examples from each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iO9Wj19_n_LO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_example[0]:  {'narrative': 'called request new york state covid relief plan day interest fee waived amex provided relief leading late payment amex refused honor relief day gap insists charging late fee', 'product': 'credit_card'}\n",
      "Test Set Shape: (490, 3)\n",
      "Gold Examples Shape: (10, 3)\n"
     ]
    }
   ],
   "source": [
    "# Separate product classifications by category\n",
    "import json\n",
    "review_1 = data[data['product'] == 'credit_card']\n",
    "review_2 = data[data['product'] == 'retail_banking']\n",
    "review_3 = data[data['product'] == 'credit_reporting']\n",
    "review_4 = data[data['product'] == 'mortgages_and_loans']\n",
    "review_5 = data[data['product'] == 'debt_collection']\n",
    "\n",
    "# Sample 2 product classifications from each category for gold examples\n",
    "gold_examples_1 = review_1.sample(2, random_state=40)\n",
    "gold_examples_2 = review_2.sample(2, random_state=40)\n",
    "gold_examples_3 = review_3.sample(2, random_state=40)\n",
    "gold_examples_4 = review_4.sample(2, random_state=40)\n",
    "gold_examples_5 = review_5.sample(2, random_state=40)\n",
    "\n",
    "# Concatenate product classification examples\n",
    "gold_examples_df = pd.concat([gold_examples_1,gold_examples_2,gold_examples_3,gold_examples_4,gold_examples_5 ])\n",
    "\n",
    "# Create the training set by excluding gold examples\n",
    "test_df = data.drop(index=gold_examples_df.index)\n",
    "\n",
    "# Convert gold examples to JSON\n",
    "columns_to_select = ['narrative', 'product']\n",
    "gold_examples_json = gold_examples_df[columns_to_select].to_json(orient='records')\n",
    "\n",
    "# Print the first record from the gold examples JSON\n",
    "print(\"gold_example[0]: \", json.loads(gold_examples_json)[0])\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Test Set Shape:\", test_df.shape)\n",
    "print(\"Gold Examples Shape:\", gold_examples_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i8taCkTwqOl"
   },
   "source": [
    "Define your **system_message**.\n",
    "\n",
    "Define **first_turn_template**, **example_template** and **prediction template**\n",
    "\n",
    "**create few shot prompt** using gold examples and system_message\n",
    "\n",
    "Randomly select 50 rows from test_df as test_data\n",
    "\n",
    "Create **mistral_response** and **mistral_response_cleaned** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iPzpBeWmzSIH"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are an AI evaluating the provided input text below to generate a singular product classification.\n",
    "A singular product classification is exactly one of:\n",
    "- credit_card\n",
    "- retail_banking\n",
    "- credit_reporting\n",
    "- mortgages_and_loans\n",
    "- debt_collection\n",
    "Be concise. Respond only with a singular product classification as defined above.\n",
    "Input text will be delimited by triple backticks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "2bPjQJs_zRoo"
   },
   "outputs": [],
   "source": [
    "mistral_first_turn_template = \"\"\"[INST]\\n <<SYS>> \\n{system_message}\\n <</SYS>>```{user_message}```[/INST]{assistant_message}\"\"\"\n",
    "mistral_examples_template = \"\"\"[INST]```{user_message}```[/INST] {assistant_message}\"\"\"\n",
    "mistral_prediction_template = \"\"\"[INST]```{user_message}```[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "X07_kNji0vTp"
   },
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(_system_message, examples_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Return a prompt message in the format expected by Mistral 7b.\n",
    "    10 examples are selected randomly as golden examples to form the\n",
    "    few-shot prompt.\n",
    "    We then loop through each example and parse the narrative as the user message\n",
    "    and the product as the assistant message.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): system message with instructions for classification\n",
    "        examples(DataFrame): A DataFrame with examples (product + narrative + summary)\n",
    "        to form the few-shot prompt.\n",
    "\n",
    "    Output:\n",
    "        few_shot_prompt (str): A prompt string in the Mistral format\n",
    "    \"\"\"\n",
    "\n",
    "    few_shot_prompt = ''\n",
    "\n",
    "    columns_to_select = ['narrative','product']\n",
    "\n",
    "    examples = (\n",
    "        examples_df.loc[:, columns_to_select].to_json(orient='records')\n",
    "    )\n",
    "\n",
    "    for idx, example in enumerate(json.loads(examples)):\n",
    "        user_input_example = example['narrative']\n",
    "        assistant_output_example = example['product']\n",
    "\n",
    "        if idx == 0:\n",
    "            few_shot_prompt += mistral_first_turn_template.format(\n",
    "                system_message=_system_message,\n",
    "                user_message=user_input_example,\n",
    "                assistant_message=assistant_output_example\n",
    "            )\n",
    "        else:\n",
    "            few_shot_prompt += mistral_examples_template.format(\n",
    "                user_message=user_input_example,\n",
    "                assistant_message=assistant_output_example\n",
    "            )\n",
    "\n",
    "    return few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "yHfPlD9o1G7M"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_few_shot_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m few_shot_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_few_shot_prompt\u001b[49m(system_message, gold_examples_df)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#print(few_shot_prompt)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_few_shot_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = create_few_shot_prompt(system_message, gold_examples_df)\n",
    "#print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "EmTmY2oq3PRv"
   },
   "outputs": [],
   "source": [
    "def fs_generate_prompt(_few_shot_prompt, _user_input):\n",
    "    _prompt =  _few_shot_prompt + mistral_prediction_template.format(user_message=_user_input)\n",
    "                                 # ^^ accessing a global variable is generally considered bad form, but whatever\n",
    "    return _prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "GKrndCFRCJhK"
   },
   "outputs": [],
   "source": [
    "def generate_mistral_response(_sys_prompt, _input_text):\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt = fs_generate_prompt(_sys_prompt, _input_text)\n",
    "\n",
    "    # Generate a response from the LLaMA model\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1200,\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=['/s'],\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "    # Extract and return the response text\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "FKYOjm7LDLJj"
   },
   "outputs": [],
   "source": [
    "# Randomly select 50 rows\n",
    "test_data = data.sample(n=50, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "JdsjoaP4DXIk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =     618.40 ms /  1200 runs   (    0.52 ms per token,  1940.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2164.04 ms /  2078 tokens (    1.04 ms per token,   960.24 tokens per second)\n",
      "llama_print_timings:        eval time =   38304.56 ms /  1199 runs   (   31.95 ms per token,    31.30 tokens per second)\n",
      "llama_print_timings:       total time =   42880.56 ms /  3277 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      55.04 ms /   106 runs   (    0.52 ms per token,  1925.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.65 ms /   506 tokens (    1.18 ms per token,   848.07 tokens per second)\n",
      "llama_print_timings:        eval time =    3348.56 ms /   105 runs   (   31.89 ms per token,    31.36 tokens per second)\n",
      "llama_print_timings:       total time =    4060.34 ms /   611 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      90.31 ms /   172 runs   (    0.53 ms per token,  1904.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     227.02 ms /   183 tokens (    1.24 ms per token,   806.10 tokens per second)\n",
      "llama_print_timings:        eval time =    5360.58 ms /   171 runs   (   31.35 ms per token,    31.90 tokens per second)\n",
      "llama_print_timings:       total time =    5782.44 ms /   354 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      55.12 ms /   106 runs   (    0.52 ms per token,  1923.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.58 ms /   506 tokens (    1.18 ms per token,   848.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3356.18 ms /   105 runs   (   31.96 ms per token,    31.29 tokens per second)\n",
      "llama_print_timings:       total time =    4071.30 ms /   611 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      23.32 ms /    49 runs   (    0.48 ms per token,  2100.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.82 ms /    75 tokens (    1.36 ms per token,   736.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1492.05 ms /    48 runs   (   31.08 ms per token,    32.17 tokens per second)\n",
      "llama_print_timings:       total time =    1645.42 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.18 ms /    47 runs   (    0.51 ms per token,  1943.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     519.11 ms /   421 tokens (    1.23 ms per token,   811.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.37 ms /    46 runs   (   31.73 ms per token,    31.52 tokens per second)\n",
      "llama_print_timings:       total time =    2026.60 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /     9 runs   (    0.50 ms per token,  1991.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     118.45 ms /    88 tokens (    1.35 ms per token,   742.92 tokens per second)\n",
      "llama_print_timings:        eval time =     246.67 ms /     8 runs   (   30.83 ms per token,    32.43 tokens per second)\n",
      "llama_print_timings:       total time =     375.49 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.21 ms /    47 runs   (    0.52 ms per token,  1941.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     518.29 ms /   421 tokens (    1.23 ms per token,   812.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1462.25 ms /    46 runs   (   31.79 ms per token,    31.46 tokens per second)\n",
      "llama_print_timings:       total time =    2029.09 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      22.08 ms /    43 runs   (    0.51 ms per token,  1947.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     524.97 ms /   433 tokens (    1.21 ms per token,   824.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1335.34 ms /    42 runs   (   31.79 ms per token,    31.45 tokens per second)\n",
      "llama_print_timings:       total time =    1904.37 ms /   475 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.24 ms /    47 runs   (    0.52 ms per token,  1938.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     521.81 ms /   421 tokens (    1.24 ms per token,   806.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1461.45 ms /    46 runs   (   31.77 ms per token,    31.48 tokens per second)\n",
      "llama_print_timings:       total time =    2032.46 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      28.20 ms /    54 runs   (    0.52 ms per token,  1915.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.44 ms /   148 tokens (    1.30 ms per token,   769.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1654.83 ms /    53 runs   (   31.22 ms per token,    32.03 tokens per second)\n",
      "llama_print_timings:       total time =    1902.40 ms /   201 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      51.53 ms /    98 runs   (    0.53 ms per token,  1901.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.00 ms /   512 tokens (    1.17 ms per token,   854.76 tokens per second)\n",
      "llama_print_timings:        eval time =    3109.09 ms /    97 runs   (   32.05 ms per token,    31.20 tokens per second)\n",
      "llama_print_timings:       total time =    3814.52 ms /   609 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.25 ms /    47 runs   (    0.52 ms per token,  1937.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     519.30 ms /   421 tokens (    1.23 ms per token,   810.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1460.96 ms /    46 runs   (   31.76 ms per token,    31.49 tokens per second)\n",
      "llama_print_timings:       total time =    2032.06 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /     9 runs   (    0.54 ms per token,  1846.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.77 ms /   233 tokens (    1.24 ms per token,   809.67 tokens per second)\n",
      "llama_print_timings:        eval time =     247.79 ms /     8 runs   (   30.97 ms per token,    32.29 tokens per second)\n",
      "llama_print_timings:       total time =     547.26 ms /   241 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      51.72 ms /    98 runs   (    0.53 ms per token,  1894.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.73 ms /   512 tokens (    1.17 ms per token,   856.57 tokens per second)\n",
      "llama_print_timings:        eval time =    3108.36 ms /    97 runs   (   32.04 ms per token,    31.21 tokens per second)\n",
      "llama_print_timings:       total time =    3815.18 ms /   609 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      23.79 ms /    46 runs   (    0.52 ms per token,  1933.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     536.31 ms /   439 tokens (    1.22 ms per token,   818.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1434.44 ms /    45 runs   (   31.88 ms per token,    31.37 tokens per second)\n",
      "llama_print_timings:       total time =    2018.86 ms /   484 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.20 ms /    47 runs   (    0.51 ms per token,  1942.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     522.31 ms /   421 tokens (    1.24 ms per token,   806.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1463.48 ms /    46 runs   (   31.81 ms per token,    31.43 tokens per second)\n",
      "llama_print_timings:       total time =    2033.09 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /     5 runs   (    0.54 ms per token,  1863.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.48 ms /   194 tokens (    1.30 ms per token,   768.37 tokens per second)\n",
      "llama_print_timings:        eval time =     122.62 ms /     4 runs   (   30.65 ms per token,    32.62 tokens per second)\n",
      "llama_print_timings:       total time =     383.12 ms /   198 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      22.08 ms /    41 runs   (    0.54 ms per token,  1856.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.36 ms /   140 tokens (    1.36 ms per token,   735.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.61 ms /    40 runs   (   31.12 ms per token,    32.14 tokens per second)\n",
      "llama_print_timings:       total time =    1477.03 ms /   180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      61.65 ms /   116 runs   (    0.53 ms per token,  1881.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     457.62 ms /   359 tokens (    1.27 ms per token,   784.49 tokens per second)\n",
      "llama_print_timings:        eval time =    3655.84 ms /   115 runs   (   31.79 ms per token,    31.46 tokens per second)\n",
      "llama_print_timings:       total time =    4242.34 ms /   474 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     5 runs   (    0.43 ms per token,  2302.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     101.65 ms /    73 tokens (    1.39 ms per token,   718.17 tokens per second)\n",
      "llama_print_timings:        eval time =     122.88 ms /     4 runs   (   30.72 ms per token,    32.55 tokens per second)\n",
      "llama_print_timings:       total time =     232.36 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     5 runs   (    0.49 ms per token,  2045.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     447.68 ms /   337 tokens (    1.33 ms per token,   752.78 tokens per second)\n",
      "llama_print_timings:        eval time =     123.96 ms /     4 runs   (   30.99 ms per token,    32.27 tokens per second)\n",
      "llama_print_timings:       total time =     578.95 ms /   341 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      21.92 ms /    42 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     138.39 ms /   112 tokens (    1.24 ms per token,   809.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1278.42 ms /    41 runs   (   31.18 ms per token,    32.07 tokens per second)\n",
      "llama_print_timings:       total time =    1463.07 ms /   153 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =     361.45 ms /   721 runs   (    0.50 ms per token,  1994.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.16 ms /   134 tokens (    1.40 ms per token,   712.18 tokens per second)\n",
      "llama_print_timings:        eval time =   22927.72 ms /   720 runs   (   31.84 ms per token,    31.40 tokens per second)\n",
      "llama_print_timings:       total time =   24199.58 ms /   854 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1936.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.10 ms /   291 tokens (    1.37 ms per token,   727.32 tokens per second)\n",
      "llama_print_timings:        eval time =      93.04 ms /     3 runs   (   31.01 ms per token,    32.24 tokens per second)\n",
      "llama_print_timings:       total time =     500.04 ms /   294 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    47 runs   (    0.51 ms per token,  1942.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     522.92 ms /   421 tokens (    1.24 ms per token,   805.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1464.90 ms /    46 runs   (   31.85 ms per token,    31.40 tokens per second)\n",
      "llama_print_timings:       total time =    2036.71 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      40.99 ms /    81 runs   (    0.51 ms per token,  1976.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     136.16 ms /   104 tokens (    1.31 ms per token,   763.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2501.83 ms /    80 runs   (   31.27 ms per token,    31.98 tokens per second)\n",
      "llama_print_timings:       total time =    2715.72 ms /   184 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      56.31 ms /   109 runs   (    0.52 ms per token,  1935.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.86 ms /   153 tokens (    1.25 ms per token,   797.44 tokens per second)\n",
      "llama_print_timings:        eval time =    3396.10 ms /   108 runs   (   31.45 ms per token,    31.80 tokens per second)\n",
      "llama_print_timings:       total time =    3699.26 ms /   261 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      54.94 ms /   106 runs   (    0.52 ms per token,  1929.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.77 ms /   506 tokens (    1.18 ms per token,   845.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3376.86 ms /   105 runs   (   32.16 ms per token,    31.09 tokens per second)\n",
      "llama_print_timings:       total time =    4091.24 ms /   611 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    20 runs   (    0.52 ms per token,  1920.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     121.45 ms /    96 tokens (    1.27 ms per token,   790.44 tokens per second)\n",
      "llama_print_timings:        eval time =     589.63 ms /    19 runs   (   31.03 ms per token,    32.22 tokens per second)\n",
      "llama_print_timings:       total time =     731.42 ms /   115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =     620.58 ms /  1200 runs   (    0.52 ms per token,  1933.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     151.72 ms /   121 tokens (    1.25 ms per token,   797.51 tokens per second)\n",
      "llama_print_timings:        eval time =   38610.31 ms /  1199 runs   (   32.20 ms per token,    31.05 tokens per second)\n",
      "llama_print_timings:       total time =   41071.62 ms /  1320 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /     9 runs   (    0.53 ms per token,  1901.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.11 ms /   135 tokens (    1.38 ms per token,   725.37 tokens per second)\n",
      "llama_print_timings:        eval time =     249.50 ms /     8 runs   (   31.19 ms per token,    32.06 tokens per second)\n",
      "llama_print_timings:       total time =     446.79 ms /   143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      40.72 ms /    78 runs   (    0.52 ms per token,  1915.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     115.47 ms /    81 tokens (    1.43 ms per token,   701.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2401.53 ms /    77 runs   (   31.19 ms per token,    32.06 tokens per second)\n",
      "llama_print_timings:       total time =    2595.25 ms /   158 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      22.23 ms /    44 runs   (    0.51 ms per token,  1979.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =      67.69 ms /    38 tokens (    1.78 ms per token,   561.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1339.50 ms /    43 runs   (   31.15 ms per token,    32.10 tokens per second)\n",
      "llama_print_timings:       total time =    1455.11 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      51.65 ms /    98 runs   (    0.53 ms per token,  1897.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.11 ms /   512 tokens (    1.17 ms per token,   851.75 tokens per second)\n",
      "llama_print_timings:        eval time =    3119.70 ms /    97 runs   (   32.16 ms per token,    31.09 tokens per second)\n",
      "llama_print_timings:       total time =    3822.95 ms /   609 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      17.76 ms /    34 runs   (    0.52 ms per token,  1914.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =      86.88 ms /    54 tokens (    1.61 ms per token,   621.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1031.72 ms /    33 runs   (   31.26 ms per token,    31.99 tokens per second)\n",
      "llama_print_timings:       total time =    1154.68 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      38.25 ms /    74 runs   (    0.52 ms per token,  1934.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     536.96 ms /   438 tokens (    1.23 ms per token,   815.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2334.89 ms /    73 runs   (   31.98 ms per token,    31.26 tokens per second)\n",
      "llama_print_timings:       total time =    2950.50 ms /   511 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      49.94 ms /    95 runs   (    0.53 ms per token,  1902.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     119.51 ms /    91 tokens (    1.31 ms per token,   761.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2936.95 ms /    94 runs   (   31.24 ms per token,    32.01 tokens per second)\n",
      "llama_print_timings:       total time =    3153.04 ms /   185 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     4 runs   (    0.49 ms per token,  2058.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =      99.29 ms /    65 tokens (    1.53 ms per token,   654.64 tokens per second)\n",
      "llama_print_timings:        eval time =      91.28 ms /     3 runs   (   30.43 ms per token,    32.86 tokens per second)\n",
      "llama_print_timings:       total time =     197.42 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      37.80 ms /    73 runs   (    0.52 ms per token,  1931.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =      58.94 ms /    29 tokens (    2.03 ms per token,   492.03 tokens per second)\n",
      "llama_print_timings:        eval time =    2247.43 ms /    72 runs   (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_print_timings:       total time =    2384.03 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.24 ms /    47 runs   (    0.52 ms per token,  1939.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     522.68 ms /   421 tokens (    1.24 ms per token,   805.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1468.67 ms /    46 runs   (   31.93 ms per token,    31.32 tokens per second)\n",
      "llama_print_timings:       total time =    2038.30 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.35 ms /    47 runs   (    0.52 ms per token,  1929.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1500.22 ms /    47 runs   (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_print_timings:       total time =    1548.89 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =     193.76 ms /   379 runs   (    0.51 ms per token,  1956.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.54 ms /   205 tokens (    1.27 ms per token,   789.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12014.31 ms /   378 runs   (   31.78 ms per token,    31.46 tokens per second)\n",
      "llama_print_timings:       total time =   12746.71 ms /   583 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      43.76 ms /    87 runs   (    0.50 ms per token,  1988.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =      56.83 ms /    25 tokens (    2.27 ms per token,   439.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2685.67 ms /    86 runs   (   31.23 ms per token,    32.02 tokens per second)\n",
      "llama_print_timings:       total time =    2831.47 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      18.17 ms /    36 runs   (    0.50 ms per token,  1981.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     521.42 ms /   420 tokens (    1.24 ms per token,   805.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.18 ms /    35 runs   (   31.81 ms per token,    31.44 tokens per second)\n",
      "llama_print_timings:       total time =    1672.02 ms /   455 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     5 runs   (    0.50 ms per token,  2009.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     304.16 ms /   256 tokens (    1.19 ms per token,   841.66 tokens per second)\n",
      "llama_print_timings:        eval time =     122.35 ms /     4 runs   (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_print_timings:       total time =     434.18 ms /   260 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      58.77 ms /   113 runs   (    0.52 ms per token,  1922.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.19 ms /   175 tokens (    1.24 ms per token,   805.73 tokens per second)\n",
      "llama_print_timings:        eval time =    3527.08 ms /   112 runs   (   31.49 ms per token,    31.75 tokens per second)\n",
      "llama_print_timings:       total time =    3869.72 ms /   287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      37.55 ms /    73 runs   (    0.51 ms per token,  1943.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.98 ms /   148 tokens (    1.30 ms per token,   770.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2259.28 ms /    72 runs   (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_print_timings:       total time =    2527.52 ms /   220 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      33.71 ms /    65 runs   (    0.52 ms per token,  1928.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =      71.71 ms /    42 tokens (    1.71 ms per token,   585.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1994.49 ms /    64 runs   (   31.16 ms per token,    32.09 tokens per second)\n",
      "llama_print_timings:       total time =    2132.01 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     633.27 ms\n",
      "llama_print_timings:      sample time =      24.33 ms /    47 runs   (    0.52 ms per token,  1931.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     521.99 ms /   421 tokens (    1.24 ms per token,   806.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1467.96 ms /    46 runs   (   31.91 ms per token,    31.34 tokens per second)\n",
      "llama_print_timings:       total time =    2037.88 ms /   467 tokens\n"
     ]
    }
   ],
   "source": [
    "# capture lenthy model timing output to variable\n",
    "%%capture gen_out\n",
    "test_data['mistral_response'] = test_data['narrative'].apply(lambda x: generate_mistral_response(few_shot_prompt, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "rA9KYTgxDh2F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No match:   This text appears to be discussing various issues related to financial products and services, including identity theft, disputes with banks or credit card companies, and debt collection. Based on the context provided, it seems most relevant to the following product classifications:\n",
      "\n",
      "* Credit reporting\n",
      "* Retail banking\n",
      "* Debt collection\n",
      "\n",
      "However, without a clear and specific request for a singular product classification based on the text itself, I cannot definitively assign one label. Therefore, I will not provide an answer at this time.\n",
      "\n",
      "No match:   This text appears to be discussing various issues related to financial products and services, including identity theft, disputes with banks or credit card companies, and debt collection. Based on the context provided, it seems most relevant to the following product classifications:\n",
      "\n",
      "* Credit reporting\n",
      "* Retail banking\n",
      "* Debt collection\n",
      "\n",
      "However, without a clear and specific request for a singular product classification based on the text itself, I cannot definitively assign one label. Therefore, I will not provide an answer at this time.\n",
      "\n",
      "No match:   This text appears to be discussing various issues related to financial products and services, including identity theft, disputes with banks or credit card companies, and debt collection. Based on the context provided, it seems most relevant to the following product classifications:\n",
      "\n",
      "* Credit reporting\n",
      "* Retail banking\n",
      "* Debt collection\n",
      "\n",
      "However, without a clear and specific request for a singular product classification based on the text itself, I cannot definitively assign one label. Therefore, I will not provide an answer at this time.\n"
     ]
    }
   ],
   "source": [
    "test_data['mistral_response_cleaned'] = test_data['mistral_response'].apply(lambda x: extract_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product\n",
       "credit_reporting       37\n",
       "credit_card             7\n",
       "mortgages_and_loans     4\n",
       "retail_banking          1\n",
       "debt_collection         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mistral_response_cleaned\n",
       "credit_reporting       27\n",
       "debt_collection        12\n",
       "mortgages_and_loans     4\n",
       "                        3\n",
       "retail_banking          2\n",
       "credit_card             2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['mistral_response_cleaned'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plQNsfl0EDSG"
   },
   "source": [
    "### **Calculate F1 score (1 Mark)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "7WXEgmPKEIoi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for 'product' and 'mistral_response_cleaned'\n",
    "f1_3 =  f1_score(test_data['product'], test_data['mistral_response_cleaned'], average=\"micro\")\n",
    "print(f'F1 Score: {f1_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdtvdEnTEZcG"
   },
   "source": [
    "### **Q17: Share your observations on the few-shot and zero-shot prompt techniques. (1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating confusion matrix\n",
    "cnf_mt = confusion_matrix(test_data['product'], test_data['mistral_response_cleaned'])\n",
    "\n",
    "# Visualizing confusion matrix using a heatmap\n",
    "num_cats = test_data['mistral_response_cleaned'].value_counts().shape[0]\n",
    "if num_cats == 5:\n",
    "  labels=['credit_card','credit_reporting','debt_collection','mortgages_and_loans','retail_banking']\n",
    "elif num_cats == 6:\n",
    "  labels=['<no-match>','credit_card','credit_reporting','debt_collection','mortgages_and_loans','retail_banking']\n",
    "\n",
    "sns.heatmap(cnf_mt, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vca9B37WGneH"
   },
   "source": [
    "# **Section 4: Text to Text generation (5 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q18: Setup prompts (1 Mark)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a **system message** as a string and assign it to the variable system_message to generate product class.** (1 Mark)**\n",
    "\n",
    "Create a **zero shot prompt template** that incorporates the system message and user input.\n",
    "\n",
    "Define **generate_prompt** function that takes both the system_message and user_input as arguments and formats them into a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "7PewmIuBII56"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "Summarize the user input below. Be specific and concise in your summary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "czkz3BMpL2ek"
   },
   "outputs": [],
   "source": [
    "zero_shot_prompt_template = \"[INST]\\n<<SYS>>{system_message}<<SYS>>\\n{user_input}\\n[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WlY1x6ACLtlL"
   },
   "outputs": [],
   "source": [
    "# Define function that combines user_prompt and system_message to create the prompt\n",
    "def t2t_generate_prompt(_system_message, _user_input):\n",
    "    _prompt = zero_shot_prompt_template.format(system_message=_system_message, user_input=_user_input)\n",
    "    return _prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "<<SYS>>\n",
      "Summarize the user input below. Be specific and concise in your summary.\n",
      "<<SYS>>\n",
      "this is the user input\n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "print(t2t_generate_prompt(system_message, \"this is the user input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0FEJZSDL2U1"
   },
   "source": [
    "Write a Python function called **generate_mistral_response** that takes a single parameter, narrative, which represents the user's complain. Inside the function, you should perform the following tasks:\n",
    "\n",
    "- **Combine the system_message and narrative to create a prompt string using generate_prompt function.**\n",
    "\n",
    "*Generate a response from the Mistral model using the lcpp_llm instance with the following parameters:*\n",
    "\n",
    "- prompt should be the combined prompt string.\n",
    "- max_tokens should be set to 1200.\n",
    "- temperature should be set to 0.\n",
    "- top_p should be set to 0.95.\n",
    "- repeat_penalty should be set to 1.2.\n",
    "- top_k should be set to 50.\n",
    "- stop should be set as a list containing '/s'.\n",
    "- echo should be set to False.\n",
    "Extract and return the response text from the generated response.\n",
    "\n",
    "Don't forget to provide a value for the system_message variable before using it in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "S-kqoM4YL1xU"
   },
   "outputs": [],
   "source": [
    "def t2t_generate_mistral_response(_sys_prompt, _input_text):\n",
    "\n",
    "    # Combine user_prompt and system_message to create the prompt\n",
    "    prompt = t2t_generate_prompt(_sys_prompt, _input_text)\n",
    "\n",
    "    # Generate a response from the LLaMA model\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1200,\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=['/s'],\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "    # Extract and return the response text\n",
    "    response_text = response[\"choices\"][0][\"text\"]\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpiIHpThMtW6"
   },
   "source": [
    "### **Q19: Generate mistral_response column containing LLM generated summaries** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Fqxl54MMMBTu"
   },
   "outputs": [],
   "source": [
    "# Randomly select 50 rows\n",
    "test_data = data.sample(n=50, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1kWS3MmUMEgc"
   },
   "outputs": [],
   "source": [
    "# capture lengthy model timing output to variable\n",
    "%%capture gen_out\n",
    "# apply generate_response function to each narrative in dataset\n",
    "test_data['mistral_response'] = test_data['narrative'].apply(lambda x: t2t_generate_mistral_response(system_message, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 167 to 387\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   product           50 non-null     object\n",
      " 1   narrative         50 non-null     object\n",
      " 2   summary           50 non-null     object\n",
      " 3   mistral_response  50 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI summary:  \n",
      "  The user is reporting a fraudulent charge of an undisclosed amount on their Capital One checking account, which was made using a debit card. The charge was immediately canceled and the user disputed it with Capital One. A provisional credit was issued to the account pending determination of the claim. However, the bank denied the claim after receiving a form letter. Despite never losing possession of their debit card, someone else used it for a fraudulent purchase. The user believes the card was intercepted and activated without their authorization. They have contacted Capital One multiple times to discuss the original claim and make a determination. Additionally, they reported the incident to local police department's financial services division regarding the fraudulent charge. A replacement card has been sent but it was activated before receiving it, allowing for unauthorized credit purchases. The user is appealing the denial of their claim with Capital One and providing them with the claim number.\n",
      "\n",
      "Reference summary:\n",
      " A fraudulent charge was made on the individual's Capital One checking account via a debit card. The transaction was immediately disputed and the card was cancelled. Capital One issued provisional credit. However, the bank later denied the claim and withdrew the provisional credit. The individual appealed the denial and had contacted Capital One multiple times, but no one reached out to discuss the original claim or decision. The original card was never lost and no authorization was given to anyone to use it. They believe a new, replacement card sent by Capital One was intercepted and fraudulently activated to make the charge. The individual is unhappy with Capital One's handling of the situation, stating that it is grossly improper to send a replacement card and allow it to be activated without authorization. They reported the fraud, have appealed the claim denial with Capital One and have also placed a complaint with their local police department and the Division of Financial Services.\n"
     ]
    }
   ],
   "source": [
    "print(\"AI summary:  \\n\", test_data['mistral_response'].iloc[0])\n",
    "print(\"\\nReference summary:\\n\", test_data['summary'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl-5fRKbND2n"
   },
   "source": [
    "### **Q20: Evaluate bert score** **(2 Marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ikncTGPBNPRb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Score: 0.35526664793491364\n"
     ]
    }
   ],
   "source": [
    "bert_scorer = evaluate.load(\"bertscore\")\n",
    "bscore = bert_scorer.compute(\n",
    "            predictions=test_data['mistral_response'],\n",
    "            references=test_data['summary'],\n",
    "            lang=\"en\",\n",
    "            rescale_with_baseline=True\n",
    "        );\n",
    "\n",
    "score = sum(bscore['f1'])/len(bscore['f1']);\n",
    "print(f'BERT Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Scores: {'rouge1': 0.494803417891791, 'rouge2': 0.17045653366638597, 'rougeL': 0.291427956721481, 'rougeLsum': 0.30613231392609996}\n"
     ]
    }
   ],
   "source": [
    "rouge_scorer = evaluate.load(\"rouge\")\n",
    "rscore = rouge_scorer.compute(\n",
    "            predictions=test_data['mistral_response'],\n",
    "            references=test_data['summary']\n",
    "        )\n",
    "print(f\"Rouge Scores: {rscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-p6_jPcVNWz7"
   },
   "source": [
    "### **Q21: Write your observation** **(1 Marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERT score of .36 is at the low end of acceptable performance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
